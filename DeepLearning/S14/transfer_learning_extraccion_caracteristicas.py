# -*- coding: utf-8 -*-
"""transfer_learning_extraccion_caracteristicas.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1poygOIzasy75VHBhcMGPAy_ewKIZX5Xr
"""

#Este código reutiliza las capas preentrenadas de MobileNetV2, ajustando solo las últimas capas para clasificar un conjunto de datos específico.
#---------------librerias----------
import tensorflow as tf
import tensorflow_datasets as tfds
from tensorflow.keras import layers, models
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.preprocessing import image_dataset_from_directory

# Cargar el dataset Flowers 102 de TensorFlow Datasets
dataset, info = tfds.load('oxford_flowers102', with_info=True, as_supervised=True)

# División en conjunto de entrenamiento y prueba
train_data = dataset['train']
test_data = dataset['test']

# Función para preprocesar imágenes
def preprocess_image(image, label):
    image = tf.image.resize(image, (224, 224))  # Cambiar tamaño a 224x224
    image = tf.keras.applications.mobilenet_v2.preprocess_input(image)  # Preprocesamiento MobileNet
    return image, label

# Aplicar preprocesamiento a los datasets
train_data = train_data.map(preprocess_image).batch(32).prefetch(tf.data.AUTOTUNE)
test_data = test_data.map(preprocess_image).batch(32).prefetch(tf.data.AUTOTUNE)

import matplotlib.pyplot as plt

# Obtener un batch de imágenes del conjunto de entrenamiento
for images, labels in train_data.take(1):
  # Mostrar las primeras 9 imágenes del batch
  for i in range(9):
    plt.subplot(3, 3, i + 1)
    plt.imshow(images[i] / 2 + 0.5) # Desnormalizar las imágenes
    plt.axis('off')
  plt.show()
  break

# 2. Cargar MobileNetV2 preentrenado
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Congelar las capas de MobileNetV2
base_model.trainable = False

# 3. Construir el modelo
model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),  # Pooling global para reducir las dimensiones
    layers.Dense(102, activation='softmax')  # Capa densa para clasificación (102 clases)
])


# 4. Compilar el modelo
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# 5. Entrenar el modelo
history = model.fit(train_data, epochs=10, validation_data=test_data)

# 6. Evaluar el modelo
test_loss, test_acc = model.evaluate(test_data)
print(f"Test accuracy: {test_acc}")

# 7. Visualizar el historial de entrenamiento
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0, 1])
plt.legend(loc='lower right')
plt.show()

import numpy as np

# 8. Realizar predicciones y mostrar algunas imágenes de prueba
for images, labels in test_data.take(1):
    predictions = model.predict(images)
    predicted_labels = np.argmax(predictions, axis=1)

    # Mostrar las primeras 9 imágenes con sus predicciones
    for i in range(9):
        plt.subplot(3, 3, i + 1)
        plt.subplots_adjust(hspace=0.5, wspace=1.5)
        plt.imshow(images[i] / 2 + 0.5)  # Desnormalizar
        plt.title(f"Predicted: {predicted_labels[i]}, True: {labels[i]}")
        plt.axis('off')
    plt.show()
    break