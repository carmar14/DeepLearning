# -*- coding: utf-8 -*-
"""clasificador_de_plantas.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19Ulgkx_OdgEzZga2929CBgJ_fTOQxfnG
"""
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
#from tensorflow.keras import datasets
#from tensorflow.keras.utils import to_categorical
from sklearn import datasets
from sklearn.model_selection import train_test_split
#from sklearn.metrics import plot_confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import confusion_matrix
import seaborn as sns
# import some data to play with
iris = datasets.load_iris() # https://archive.ics.uci.edu/ml/datasets/iris
X = iris.data # características
y = iris.target # etiquetas (0, 1, 2)

# Crear un DataFrame para facilitar la visualización
df = pd.DataFrame(X, columns=iris.feature_names)
df['species'] = iris.target

# Mapeo de especies a nombres
df['species'] = df['species'].map({0: 'Setosa', 1: 'Versicolor', 2: 'Virginica'})

# Configurar la paleta de colores
palette = {'Setosa': 'red', 'Versicolor': 'green', 'Virginica': 'blue'}

# Crear la figura y los ejes
plt.figure(figsize=(10, 6))

# Graficar las características
sns.scatterplot(data=df, x='sepal length (cm)', y='sepal width (cm)', hue='species', palette=palette, s=100)

# Agregar título y etiquetas
plt.title('Características del Iris')
plt.xlabel('Longitud del sépalo (cm)')
plt.ylabel('Anchura del sépalo (cm)')

# Mostrar leyenda
plt.legend(title='Especies')

# Mostrar la gráfica
plt.grid()
#plt.show()

class_names = iris.target_names
labels, counts = np.unique(y, return_counts=True)
plt.figure()
plt.bar(labels, counts, align='center')
plt.gca().set_xticks(labels)
#plt.show()

from mpl_toolkits.mplot3d import Axes3D
# Configurar la paleta de colores
colors = {'Setosa': 'red', 'Versicolor': 'green', 'Virginica': 'blue'}
# Crear la figura y los ejes 3D
fig = plt.figure(figsize=(12, 8))
ax = fig.add_subplot(111, projection='3d')

# Graficar las características en 3D
for species in colors.keys():
    subset = df[df['species'] == species]
    ax.scatter(subset.iloc[:, 0], subset.iloc[:, 1], subset.iloc[:, 2],
               color=colors[species], label=species, s=100)

# Agregar etiquetas y título
ax.set_title('Características del Iris en 3D')
ax.set_xlabel('Longitud del sépalo (cm)')
ax.set_ylabel('Anchura del sépalo (cm)')
ax.set_zlabel('Longitud del pétalo (cm)')

# Mostrar leyenda
ax.legend(title='Especies')

# Mostrar la gráfica
#plt.show()

print("Las caracteristicas: \n", X)
print("Las estiquetas son : \n", y)
#Converting the dataset to pandas dataframe
iris = pd.DataFrame(
    data= np.c_[iris['data'], iris['target']],
    columns= iris['feature_names'] + ['target']
    )
print (iris)

y = pd.get_dummies(y).values
print("Datos one hot encoding \n :", y)

# Split the data into a training set and a test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

# Definir el modelo secuencial
# Crear el modelo
model = tf.keras.Sequential()
#Define a model

# Capa de entrada y capa oculta (se ajusta a la cantidad de características de entrada)
model.add(tf.keras.layers.Dense(units=64, input_dim=X.shape[1], activation='tanh'))  # Capa oculta con 'tanh'
model.add(tf.keras.layers.Dense(units=32, activation='tanh'))  # Capa oculta con 'tanh'
# Capa de salida para 3 clases con 'softmax' para clasificación multiclase
model.add(tf.keras.layers.Dense(units=3, activation='softmax'))

#Compile and train the model
model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])
history = model.fit(X_train, y_train, validation_split=0.3, batch_size=55, epochs=100)
#history = model.fit(X_train, y_train, batch_size=5, epochs=100)

# list all data in history
print(history.history.keys())
# summarize history for accuracy
plt.figure()
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
#plt.legend(['train'], loc='upper left')
plt.legend(['train', 'test'], loc='upper left')
#plt.show()
# summarize history for loss
plt.figure()
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
#plt.legend(['train'], loc='upper left')
plt.legend(['train', 'test'], loc='upper left')
#plt.show()

# Evaluate the model with test data
loss, accuracy = model.evaluate(X_test, y_test, verbose=0)
print('Test loss:', loss)
print('Test accuracy:', accuracy)

#Predict test data
y_pred = model.predict(X_test)
print("Salidas predichas", y_pred)
#Print actual and predicted value
actual = np.argmax(y_test,axis=1)
predicted = np.argmax(y_pred,axis=1)
print(f"Actual: {actual}")
print(f"Predicted: {predicted}")

#--------matrix confusion-----

# Compute confusion matrix
print(y_test)
print(y_pred)
#cm = confusion_matrix(y_test, y_pred)
cm = confusion_matrix(actual, predicted)

print(cm)

# Show confusion matrix in a separate window
plt.matshow(cm)
plt.title('Confusion matrix')
plt.colorbar()
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()