# -*- coding: utf-8 -*-
"""regresion_cnn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FyDiP8uKdeWiXlRjlG1HviQWY5_fmXHD
"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.datasets import mnist
import matplotlib.pyplot as plt

# Cargar el dataset MNIST
(X_train, y_train), (X_test, y_test) = mnist.load_data()

# Normalizar los datos de entrada (los valores de los píxeles estarán entre 0 y 1)
X_train = X_train.astype('float32') / 255.0
X_test = X_test.astype('float32') / 255.0

# Añadir una dimensión adicional para el canal de color (1, ya que son imágenes en escala de grises)
X_train = np.expand_dims(X_train, axis=-1)
X_test = np.expand_dims(X_test, axis=-1)

# Convertir las etiquetas a valores flotantes para regresión
y_train = y_train.astype('float32')
y_test = y_test.astype('float32')

# Definir el modelo de la red neuronal convolucional para regresión
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),  # Capa convolucional con 32 filtros de 3x3
    MaxPooling2D((2, 2)),  # Capa de MaxPooling con tamaño de 2x2
    Conv2D(64, (3, 3), activation='relu'),  # Segunda capa convolucional con 64 filtros
    MaxPooling2D((2, 2)),  # Segunda capa de MaxPooling
    Flatten(),  # Aplanar la salida para la capa completamente conectada
    Dense(64, activation='relu'),  # Capa totalmente conectada con 64 neuronas
    Dropout(0.5),  # Dropout para reducir el sobreajuste
    Dense(1)  # Capa de salida con una sola neurona para la regresión (valor continuo)
])

# Compilar el modelo
model.compile(optimizer='adam',
              loss='mean_squared_error')  # Pérdida MSE para problemas de regresión

# Entrenar el modelo
history = model.fit(X_train, y_train, epochs=20, batch_size=64, validation_data=(X_test, y_test), verbose=1)

# Evaluar el modelo en el conjunto de prueba
test_loss = model.evaluate(X_test, y_test, verbose=0)
print(f"Pérdida en el conjunto de prueba (MSE): {test_loss:.2f}")

# Realizar predicciones en el conjunto de prueba
y_pred = model.predict(X_test)

# Graficar los valores reales vs los valores predichos para algunas muestras
plt.figure(figsize=(12, 6))
for i in range(10):
    plt.subplot(2, 5, i+1)
    plt.imshow(X_test[i].reshape(28, 28), cmap='gray')
    plt.title(f"Real: {y_test[i]}\nPredicción: {y_pred[i][0]:.2f}")
    plt.axis('off')
plt.tight_layout()
plt.show()

# Graficar la pérdida durante el entrenamiento
epochs = range(1, len(history.history['loss']) + 1)
plt.figure(figsize=(10, 5))
plt.plot(epochs, history.history['loss'], label='Pérdida en Entrenamiento')
plt.plot(epochs, history.history['val_loss'], label='Pérdida en Validación')
plt.title('Pérdida (MSE) durante el Entrenamiento')
plt.xlabel('Épocas')
plt.ylabel('Pérdida (MSE)')
plt.legend()
plt.show()