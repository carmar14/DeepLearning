# -*- coding: utf-8 -*-
"""clasificador_de_plantas.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19Ulgkx_OdgEzZga2929CBgJ_fTOQxfnG
"""
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, roc_curve
from sklearn.preprocessing import label_binarize
import seaborn as sns
# import some data to play with
iris = datasets.load_iris() # https://archive.ics.uci.edu/ml/datasets/iris
X = iris.data # características
y = iris.target # etiquetas (0, 1, 2)

# Crear un DataFrame para facilitar la visualización
df = pd.DataFrame(X, columns=iris.feature_names)
df['species'] = iris.target

# Mapeo de especies a nombres
df['species'] = df['species'].map({0: 'Setosa', 1: 'Versicolor', 2: 'Virginica'})

# Configurar la paleta de colores
palette = {'Setosa': 'red', 'Versicolor': 'green', 'Virginica': 'blue'}

# Crear la figura y los ejes
plt.figure(figsize=(10, 6))

# Graficar las características
sns.scatterplot(data=df, x='sepal length (cm)', y='sepal width (cm)', hue='species', palette=palette, s=100)

# Agregar título y etiquetas
plt.title('Características del Iris')
plt.xlabel('Longitud del sépalo (cm)')
plt.ylabel('Anchura del sépalo (cm)')

# Mostrar leyenda
plt.legend(title='Especies')

# Mostrar la gráfica
plt.grid()
#plt.show()

class_names = iris.target_names
labels, counts = np.unique(y, return_counts=True)
plt.figure()
plt.bar(labels, counts, align='center')
plt.gca().set_xticks(labels)
#plt.show()

from mpl_toolkits.mplot3d import Axes3D
# Configurar la paleta de colores
colors = {'Setosa': 'red', 'Versicolor': 'green', 'Virginica': 'blue'}
# Crear la figura y los ejes 3D
fig = plt.figure(figsize=(12, 8))
ax = fig.add_subplot(111, projection='3d')

# Graficar las características en 3D
for species in colors.keys():
    subset = df[df['species'] == species]
    ax.scatter(subset.iloc[:, 0], subset.iloc[:, 1], subset.iloc[:, 2],
               color=colors[species], label=species, s=100)

# Agregar etiquetas y título
ax.set_title('Características del Iris en 3D')
ax.set_xlabel('Longitud del sépalo (cm)')
ax.set_ylabel('Anchura del sépalo (cm)')
ax.set_zlabel('Longitud del pétalo (cm)')

# Mostrar leyenda
ax.legend(title='Especies')

# Mostrar la gráfica
#plt.show()

print("Las caracteristicas: \n", X)
print("Las estiquetas son : \n", y)
#Converting the dataset to pandas dataframe
iris = pd.DataFrame(
    data= np.c_[iris['data'], iris['target']],
    columns= iris['feature_names'] + ['target']
    )
print (iris)

y = pd.get_dummies(y).values
print("Datos one hot encoding \n :", y)

# Split the data into a training set and a test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

# Definir el modelo secuencial
# Crear el modelo
model = tf.keras.Sequential()
#Define a model

# Capa de entrada y capa oculta (se ajusta a la cantidad de características de entrada)
model.add(tf.keras.layers.Dense(units=64, input_dim=X.shape[1], activation='tanh'))  # Capa oculta con 'tanh'
model.add(tf.keras.layers.Dense(units=32, activation='tanh'))  # Capa oculta con 'tanh'
# Capa de salida para 3 clases con 'softmax' para clasificación multiclase
model.add(tf.keras.layers.Dense(units=3, activation='softmax'))

#Compile and train the model
model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])
history = model.fit(X_train, y_train, validation_split=0.3, batch_size=15, epochs=100)
#history = model.fit(X_train, y_train, batch_size=5, epochs=100)

# list all data in history
print(history.history.keys())
# summarize history for accuracy
plt.figure()
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
#plt.legend(['train'], loc='upper left')
plt.legend(['train', 'test'], loc='upper left')
#plt.show()
# summarize history for loss
plt.figure()
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
#plt.legend(['train'], loc='upper left')
plt.legend(['train', 'test'], loc='upper left')
#plt.show()

# Evaluate the model with test data
loss, accuracy = model.evaluate(X_test, y_test, verbose=0)
print('Test loss:', loss)
print('Test accuracy:', accuracy)

#Predict test data
y_pred = model.predict(X_test)
print("Salidas predichas", y_pred)
#Print actual and predicted value
actual = np.argmax(y_test,axis=1)
predicted = np.argmax(y_pred,axis=1)
print(f"Actual: {actual}")
print(f"Predicted: {predicted}")

#--------matrix confusion-----

# Compute confusion matrix
print("datos reales", y_test)
print("datos predichos", predicted)
#cm = confusion_matrix(y_test, y_pred)
cm = confusion_matrix(actual, predicted)

print(cm)

# Show confusion matrix in a separate window
plt.matshow(cm)
plt.title('Confusion matrix')
plt.colorbar()
plt.ylabel('True label')
plt.xlabel('Predicted label')

#------metricas------
n_classes = 3
y_true = actual
# Binarizar las etiquetas para ROC AUC
y_true_bin = label_binarize(y_true, classes=[0, 1, 2])
# Calcular Precision, Recall, F1-Score y Accuracy para el problema multiclase
precision_macro = precision_score(y_true, predicted, average='macro')
recall_macro = recall_score(y_true, predicted, average='macro')
f1_macro = f1_score(y_true, predicted, average='macro')
accuracy = accuracy_score(y_true, predicted)

# Calcular AUC (Area Under the Curve) para cada clase
auc = roc_auc_score(y_true_bin, y_pred, multi_class="ovr")

# Mostrar las métricas
print(f'Precisión (Macro): {precision_macro:.2f}')
print(f'Recall (Macro): {recall_macro:.2f}')
print(f'F1-Score (Macro): {f1_macro:.2f}')
print(f'Exactitud (Accuracy): {accuracy:.2f}')
print(f'AUC (OvR): {auc:.2f}')

# Calcular ROC curve para cada clase
fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred[:, i])
    roc_auc[i] = roc_auc_score(y_true_bin[:, i], y_pred[:, i])

# Graficar las curvas ROC para cada clase
plt.figure()
colors = ['blue', 'green', 'red']
for i, color in zip(range(n_classes), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=2, label=f'Clase {i} (AUC = {roc_auc[i]:.2f})')

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('Tasa de Falsos Positivos')
plt.ylabel('Tasa de Verdaderos Positivos')
plt.title('Curvas ROC para Clasificación Multiclase')
plt.legend(loc="lower right")
plt.show()

