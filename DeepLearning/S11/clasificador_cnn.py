# -*- coding: utf-8 -*-
"""clasificador_CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HPQqka_JXLCWPfRYkjVyxVUIcismtIFv
"""

#---------librerias-------
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt

# Cargar el dataset CIFAR-10
(X_train, y_train), (X_test, y_test) = cifar10.load_data()

# Normalizar los datos de entrada (los valores de los píxeles estarán entre 0 y 1)
X_train = X_train.astype('float32') / 255.0
X_test = X_test.astype('float32') / 255.0

# Convertir las etiquetas a formato one-hot encoding
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)

# Definir el modelo de la red neuronal convolucional
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),  # Capa convolucional con 32 filtros de 3x3
    MaxPooling2D((2, 2)),  # Capa de MaxPooling con tamaño de 2x2
    Conv2D(64, (3, 3), activation='relu'),  # Segunda capa convolucional con 64 filtros
    MaxPooling2D((2, 2)),  # Segunda capa de MaxPooling
    Conv2D(128, (3, 3), activation='relu'),  # Tercera capa convolucional con 128 filtros
    Flatten(),  # Aplanar la salida para la capa completamente conectada
    Dense(128, activation='relu'),  # Capa totalmente conectada con 128 neuronas
    Dropout(0.5),  # Dropout para reducir el sobreajuste
    Dense(10, activation='softmax')  # Capa de salida con activación softmax para clasificación de 10 clases
])

# Compilar el modelo
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Entrenar el modelo
history = model.fit(X_train, y_train, epochs=20, batch_size=64, validation_data=(X_test, y_test), verbose=1)

# Evaluar el modelo en el conjunto de prueba
test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)
print(f"Exactitud en el conjunto de prueba: {test_acc:.2f}")

# Graficar la precisión y la pérdida del entrenamiento
epochs = range(1, len(history.history['accuracy']) + 1)

plt.figure(figsize=(12, 5))

# Gráfico de la precisión
plt.subplot(1, 2, 1)
plt.plot(epochs, history.history['accuracy'], label='Precisión en Entrenamiento')
plt.plot(epochs, history.history['val_accuracy'], label='Precisión en Validación')
plt.title('Precisión durante el Entrenamiento')
plt.xlabel('Épocas')
plt.ylabel('Precisión')
plt.legend()

# Gráfico de la pérdida
plt.subplot(1, 2, 2)
plt.plot(epochs, history.history['loss'], label='Pérdida en Entrenamiento')
plt.plot(epochs, history.history['val_loss'], label='Pérdida en Validación')
plt.title('Pérdida durante el Entrenamiento')
plt.xlabel('Épocas')
plt.ylabel('Pérdida')
plt.legend()

plt.tight_layout()
plt.show()

# Realizar predicciones en el conjunto de prueba
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_test = np.argmax(y_test, axis=1)

#print("clases de prueba", np.argmax(y_test,axis=1))

# Diccionario de clases para CIFAR-10
class_names = ['avión', 'automóvil', 'pájaro', 'gato', 'ciervo', 'perro', 'rana', 'caballo', 'barco', 'camión']
#print(f"Real: {class_names[int(y_test[1][0])]}\nPredicción: {class_names[y_pred_classes[1]]}")

# Mostrar las primeras 10 imágenes del conjunto de prueba junto con sus predicciones
plt.figure(figsize=(12, 6))
for i in range(10):
    plt.subplot(2, 5, i+1)
    plt.imshow(X_test[i])
    plt.title(f"Real: {class_names[y_test[i]]}\nPredicción: {class_names[y_pred_classes[i]]}")
    plt.axis('off')
plt.tight_layout()
plt.show()